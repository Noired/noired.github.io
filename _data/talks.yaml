# -
#   month:
#   year:
#   title:
#   playback:
#   venue:
#   slides:
#   link:
#   tldr:
#   co:
#   works: 
-
  month: 7
  year: 2025
  title: "Lecture: 'Graph Learning, Equivariance and Expressiveness'"
  venue: Course on Groups and Deep Learning at Technion – Lecture
  slides: https://drive.google.com/file/d/1v9XeybbO8i_YmV69OOxBZL2uewLmxTv4/view?usp=sharing
  tldr: "In this lecture, I discuss learning on graphs and its key challenges, focusing on the interplay between equivariance, expressive power, and computational complexity. I present a coherent narrative that introduces these core aspects and highlights recent research aimed at navigating the trade-offs between them. We begin with feature augmentation techniques, including random feature identifiers, symmetrization methods, and substructure encodings. The lecture then transitions to the broader class of Subgraph GNNs, which aim to combine the strengths of these techniques while maintaining a domain-agnostic design."
-
  month: 12
  year: 2024
  title: "Keynote: 'Advances in Subgraph GNNs for Expressive and Efficient Learning on Graphs'"
  venue: "LoG 2024 Italian Meetup (Keynote Speaker)"
  slides: https://drive.google.com/file/d/1Qr233RTJgl2D2QxXMN926hUlth-w3equ/view?usp=sharing
  tldr: "In this keynote talk, I discuss recent advances in Graph Representation Learning, with a focus on Subgraph Graph Neural Networks (Subgraph GNNs) as more expressive alternatives to traditional message-passing approaches. I begin by exploring the concept of expressive power and the limitations of conventional methods before introducing Subgraph GNNs. While these models offer greater flexibility and expressiveness, they come with the challenge of high computational complexity due to modeling graphs as bags of subgraphs. At the core of the talk, I present HyMN, a novel Subgraph GNN that balances efficiency and expressiveness through subgraph sampling and Structural Encodings (SEs). By leveraging walk-based node centrality measures, HyMN effectively reduces subgraph sizes while enhancing discriminative power and maintaining computational feasibility."
  works:
    - https://arxiv.org/abs/2110.02910
    - https://arxiv.org/abs/2206.11140
    - https://arxiv.org/abs/2501.03113
-
  month: 7
  year: 2024
  title: "Panel: 'The future and challenges of Graph Learning'"
  venue: "Graph Learning Social @ ICML 2024 (Panelist)"
  link: https://x.com/maxthiessen_ml/status/1816104205314097286
  tldr: "I took part as a panelist at ICML 2024 Graph Learning Social's panel to discuss on the future and challenges related to Machine Learning on graphs."
-
  month: 3
  year: 2024
  title: "Towards Expressive and Efficient Graph Neural Networks"
  venue: "Prof. Thomas Gärtner's ML research unit at TU Wien"
  slides: https://drive.google.com/file/d/1Hth4YJZiV9afPWdWwR5xxDeFxr_WE6OK/view?usp=drive_link
  tldr: "A presentation on the main work underpinning my PhD thesis. We discuss jointly, in a coherent and gradual fashion, the contributions I made on designing expressive and efficient Graph Neural Networks. We begin by exploring neural architectures on simplicial complexes, a generalization of graphs that captures group-wise interactions. By lifting graphs to simplicial complexes via complete subgraphs, we introduce a hierarchical message-passing approach that surpasses traditional node-centric MPNNs. Extending this, we consider regular cell complexes, incorporating structures like simple and induced cycles for enhanced expressiveness and performance, particularly in molecular modeling. Next, we present an alternative approach that models graphs as bags of subgraphs selected by predefined policies. We design an architecture that respects symmetries, achieving high expressiveness even with efficient, weak message-passing encoders. Finally, we provide a theoretical framework, unifying related works under the bags-of-subgraphs paradigm. A novel symmetry analysis offers an upper bound on expressiveness and defines a design space for future architectures."
  works:
    - https://arxiv.org/abs/2103.03212
    - https://arxiv.org/abs/2106.12575
    - https://arxiv.org/abs/2110.02910
    - https://arxiv.org/abs/2206.11140
-
  month: 3
  year: 2023
  title: "Pack your subgraphs: A journey into subgraphs for powerful Graph Neural Networks"
  venue: "Yves-Alexandre de Montjoye's Group Talks (Imperial College London)"
  works: 
    - https://arxiv.org/abs/2206.11140
    - https://arxiv.org/abs/2110.02910
  tldr: "Our latest two works on subgraphs for more expressive GNNs lined up to tell a coherent story. In the first part of the talk we show the design of a novel framework (ESAN) to process generic bags of subgraphs in an equivariant manner. We show that this approach effectively increases the expressive power of MPNNs. Then, we notice a surge in concurrent approaches which – sometimes unwittingly – make use of subgraphs for powerful graph representations. In the second part, a novel symmetry analysis allows to unify and better characterise these approaches when using a node-based selection policy. We prove an upper-bound on their expressive power and conceive a framework serving as a design space for equivariant node-based subgraph methods."
-
  month: 3
  year: 2023
  title: "Lecture: 'Pack your subgraphs: A journey into subgraphs for powerful Graph Neural Networks'"
  venue: Course on Geometric Deep Learning at Oxford University – Lecture
  link: https://twitter.com/mmbronstein/status/1633062949282541569
  slides: https://drive.google.com/file/d/1nM6eySsxjmnFtburRhqjQ1gw09o5iO7P/view?usp=sharing
  works: 
    - https://arxiv.org/abs/2206.11140
    - https://arxiv.org/abs/2110.02910
  tldr: "Our latest two works on subgraphs for more expressive GNNs lined up to tell a coherent story. In the first part of the talk we show the design of a novel framework (ESAN) to process generic bags of subgraphs in an equivariant manner. We show that this approach effectively increases the expressive power of MPNNs. Then, we notice a surge in concurrent approaches which – sometimes unwittingly – make use of subgraphs for powerful graph representations. In the second part, a novel symmetry analysis allows to unify and better characterise these approaches when using a node-based selection policy. We prove an upper-bound on their expressive power and conceive a framework serving as a design space for equivariant node-based subgraph methods."
-
  month: 12
  year: 2022
  title: "Exploring the practical and theoretical landscape of expressive Graph Neural Networks"
  playback: https://www.youtube.com/watch?v=ASQYjbUBYzs
  venue: Learning on Graphs Conference 2022
  slides: https://drive.google.com/drive/folders/1Q3PjpuP7FoY38Ik79R21k67tiA5p8uey
  link: https://logconference.org/schedule-tutorials/#exploring-the-practical-and-theoretical-landscape-of-expressive-graph-neural-networks
  tldr: "The tutorial reviews the most prominent expressive GNNs, categorises them into different families, and draws interesting connections between them. This is accomplished through a series of practical coding sessions and an organic overview of the literature landscape. We aim to convey the importance of studying the expressive power of GNNs and make this field more accessible to our community, especially practitioners and newcomers."
  co:
    - Beatrice Bevilacqua
    - Haggai Maron
-
  month: 11
  year: 2022
  title: "Understanding and Extending Subgraph GNNs by Rethinking their Symmetries"
  venue: Learning on Graphs and Geometry Reading Group
  link: https://twitter.com/HannesStaerk/status/1592174079892594688
  playback: https://www.youtube.com/watch?v=M5owHERuVcE
  tldr: "Many concurrent works seem to share a similar underlying intuition: to represent a graph by processing subgraphs generated via some simple selection policy. Inspired by a novel symmetry analyses for the most prominent of these methods – those where subgraphs are in a 1:1 correspondence with nodes in the original graph – we prove an upper-bound on their expressive power and conceive a framework serving as a design space for future new equivariant node-based subgraph architectures."
  co:
    - Beatrice Bevilacqua
  works: 
    - https://arxiv.org/abs/2206.11140
-
  month: 11
  year: 2022
  title: "Pack your subgraphs: A journey into subgraphs for powerful Graph Neural Networks"
  venue: "Simone Scardapane's Group Talks (Sapienza)"
  link: https://www.sscardapane.it/seminars/subgraph-gnn
  tldr: "We line up our latest two works on subgraphs for more expressive GNNs to tell a coherent story. In the first part of the talk we show the design of a novel framework (ESAN) to process generic bags of subgraphs in an equivariant manner. We show that this approach effectively increases the expressive power of MPNNs. Then, we notice a surge in concurrent approaches which – sometimes unwittingly – make use of subgraphs for powerful graph representations. In the second part, a novel symmetry analysis allows to unify and better characterise these approaches when using a node-based selection policy. We prove an upper-bound on their expressive power and conceive a framework serving as a design space for equivariant node-based subgraph methods."
  co:
    - Beatrice Bevilacqua
  works: 
    - https://arxiv.org/abs/2206.11140
    - https://arxiv.org/abs/2110.02910
-
  month: 7
  year: 2022
  title: "Pack your subgraphs: A journey into subgraphs for powerful Graph Neural Networks"
  venue: Meta AI orgs Reading Meeting
  tldr: "We line up our latest two works on subgraphs for more expressive GNNs to tell a coherent story. In the first part of the talk we show the design of a novel framework (ESAN) to process generic bags of subgraphs in an equivariant manner. We show that this approach effectively increases the expressive power of MPNNs. Then, we notice a surge in concurrent approaches which – sometimes unwittingly – make use of subgraphs for powerful graph representations. In the second part, a novel symmetry analysis allows to unify and better characterise these approaches when using a node-based selection policy. We prove an upper-bound on their expressive power and conceive a framework serving as a design space for equivariant node-based subgraph methods."
  co:
    - Beatrice Bevilacqua
  works: 
    - https://arxiv.org/abs/2206.11140
    - https://arxiv.org/abs/2110.02910
-
  month: 7
  year: 2022
  title: "Pack your subgraphs: A journey into subgraphs for powerful Graph Neural Networks"
  venue: "Maks Ovsjanikov's Group Talks (École Polytechnique, France)"
  link: https://www.lix.polytechnique.fr/~maks/
  tldr: "We line up our latest two works on subgraphs for more expressive GNNs to tell a coherent story. In the first part of the talk we show the design of a novel framework (ESAN) to process generic bags of subgraphs in an equivariant manner. We show that this approach effectively increases the expressive power of MPNNs. Then, we notice a surge in concurrent approaches which – sometimes unwittingly – make use of subgraphs for powerful graph representations. In the second part, a novel symmetry analysis allows to unify and better characterise these approaches when using a node-based selection policy. We prove an upper-bound on their expressive power and conceive a framework serving as a design space for equivariant node-based subgraph methods."
  co:
    - Beatrice Bevilacqua
  works: 
    - https://arxiv.org/abs/2206.11140
    - https://arxiv.org/abs/2110.02910
-
  month: 7
  year: 2022
  title: "Subgraphs for more expressive GNNs"
  playback: https://www.youtube.com/watch?v=PxJ5o4y4FUA
  venue: Course on Geometric Deep Learning at the African Master's on Machine Intelligence (GDL100) – Seminar
  slides: https://www.dropbox.com/s/tnuhppf1fqmv6y9/AIMS%202022%20-%20Seminar%202%20-%20Subgraph%20GNNs.pdf?dl=0
  link: https://geometricdeeplearning.com/lectures/
  tldr: "Many concurrent works seem to share a similar underlying intuition: to represent a graph by processing subgraphs generated via some simple selection policy. We discuss these methods together and try to find a common characterisation, while showing that the architecture proposed in our previous work 'Equivariant Subgraph Aggregation Networks' subsumes most of them."
  works: 
    - https://arxiv.org/abs/2110.02910
-
  month: 3
  year: 2022
  title: "Graph Representation Learning on Simplicial and Cellular Complexes"
  venue: "Dagstuhl Seminars – Graph Embeddings: Theory meets Practice"
  link: https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=22132
  tldr: "I gather together our works on message-passing on Simplicial and Cellular Complexes and present them together showing how these approaches in turn allow for more expressive graph representations."
  works:
    - https://arxiv.org/abs/2106.12575
    - https://arxiv.org/abs/2103.03212
-
  month: 2
  year: 2022
  title: "Equivariant Subgraph Aggregation Networks"
  playback: https://www.youtube.com/watch?v=VYZog7kbXks
  venue: Author Interviews with Zak Jost
  link: https://twitter.com/ZakJost/status/1504154214515163139
  tldr: "We explore the idea of modeling a graph as a bag of subgraphs generated by simple, domain agnostic selection policies, such as node-deletion, edge-deletion, ego-networks. We formally show that this approach lead to the design Graph Neural Networks which can be made strictly more powerful than standard Message Passing ones. We prove this by defining a novel WL variant and by constructing layers equivariant to the emerging symmetry group."
  co:
    - Derek Lim
    - Beatrice Bevilacqua
  works: 
    - https://arxiv.org/abs/2110.02910
-
  month: 12
  year: 2021
  title: "Subgraph Networks"
  playback: https://www.youtube.com/watch?v=hkb4pgPoz0Y
  venue: Third Nepal Winter School in AI
  link: https://twitter.com/naamii_nepal/status/1579137847218491392
  tldr: "Many concurrent works seem to share a similar underlying intuition: to represent a graph by processing subgraphs generated via some simple selection policy. We discuss these methods together and try to find a common characterisation, while showing that the architecture proposed in our previous work 'Equivariant Subgraph Aggregation Networks' subsumes most of them."
  works: 
    - https://arxiv.org/abs/2110.02910
-
  month: 12
  year: 2021
  title: "Equivariant Subgraph Aggregation Networks"
  playback: https://www.youtube.com/watch?v=voMue3G-_vk
  venue: Learning on Graphs and Geometry Reading Group
  link: https://twitter.com/HannesStaerk/status/1470424178117558274
  tldr: "We explore the idea of modeling a graph as a bag of subgraphs generated by simple, domain agnostic selection policies, such as node-deletion, edge-deletion, ego-networks. We formally show that this approach lead to the design Graph Neural Networks which can be made strictly more powerful than standard Message Passing ones. We prove this by defining a novel WL variant and by constructing layers equivariant to the emerging symmetry group."
  co:
    - Derek Lim
    - Beatrice Bevilacqua
  works: 
    - https://arxiv.org/abs/2110.02910
-
  month: 10
  year: 2021
  title: "Graph Convolutional Network for Disease Prediction with Imbalanced Data – Anees Kazi"
  playback: https://www.youtube.com/watch?v=sUYnB6LnYPw
  venue: London Machine Learning Meetup (Moderator)
  link: https://www.meetup.com/London-Machine-Learning-Meetup/
  tldr: I moderate Anees Kazi's talk at the London Machine Learning Meetup.
-
  month: 8
  year: 2021
  title: "Weisfeiler and Lehman Go Cellular: CW Networks"
  playback: https://www.youtube.com/watch?v=MTQGNVTn9lQ
  venue: Learning on Graphs and Geometry Reading Group
  link: https://twitter.com/HannesStaerk/status/1434903774645026820
  tldr: "We extend message-passing from graphs and Simplicial Complexes to Cellular Complexes, combinatorial topological spaces generalising these two. By lifting graphs to Cellular Complexes we can naturally model molecules and unlock a series of advantages w.r.t. standard pairwise message-passing."
  co:
    - Cristian Bodnar
  works:
    - https://arxiv.org/abs/2106.12575
- 
  month: 8
  year: 2021
  title: "Weisfeiler and Lehman Go Topological: Message Passing Simplicial Networks"
  venue: Course on Geometric Deep Learning at the African Master's on Machine Intelligence (GDL100) – Seminar
  link: https://geometricdeeplearning.com/lectures_2021/
  slides: https://www.dropbox.com/s/sai0wgh46zwd1b3/AMMI%20Seminar%204%20-%20Message%20Passing%20Simplicial%20Networks.pdf?dl=0
  tldr: "We re-define colour refinement and message-passing on Simplicial Complexes, topological generalisation of graphs. This allows to model higher-order interactions, model meso-scale structures and increase the expressive power of Graph Neural Networks."
  works:
    - https://arxiv.org/abs/2103.03212
-
  month: 7
  year: 2021
  title: "The expressive power of GNNs by the WL test"
  venue: London Geometry and Machine Learning Summer School 2021 – Tutorial
  link: https://www.logml.ai/archive
  tldr: "What is the current state of affair in provably more expressive Graph Neural Networks? Giorgos Bouritsas and I lead and moderate this interactive discussion on approaches to go beyond 1-WL discriminating power. Ultimately, we would like to tackle the following question: 'Is the Weisfeiler-Leman hierarchy suitable to study the representational power of learning models on graphs? Do we necessarily need to go beyond message-passing?'"
  co:
    - Giorgos Bouritsas
-
  month: 6
  year: 2021
  title: "Weisfeiler and Lehman Go Topological: Message Passing Simplicial Networks"
  venue: TopoNets 2021 – Networks Beyond Pairwise Interactions
  link: https://sites.google.com/view/toponets2021/home-page?pli=1
  tldr: "We re-define colour refinement and message-passing on Simplicial Complexes, topological generalisation of graphs. This allows to model higher-order interactions, model meso-scale structures and increase the expressive power of Graph Neural Networks."
  co:
    - Cristian Bodnar
  works:
    - https://arxiv.org/abs/2103.03212
-
  month: 5
  year: 2021
  title: "Weisfeiler and Lehman Go Topological: Message Passing Simplicial Networks"
  venue: Artificial Intelligence Research Group Talks (Cambridge University)
  link: http://talks.cam.ac.uk/talk/index/159697
  tldr: "We re-define colour refinement and message-passing on Simplicial Complexes, topological generalisation of graphs. This allows to model higher-order interactions, model meso-scale structures and increase the expressive power of Graph Neural Networks."
  co:
    - Cristian Bodnar
    - Yu Guang Wang
  works:
    - https://arxiv.org/abs/2103.03212
-
  month: 4
  year: 2021
  title: "Weisfeiler and Lehman Go Topological: Message Passing Simplicial Networks"
  venue: Graph Journal Club (Valence AI)
  link: https://twitter.com/valence_ai/status/1383026981546131460
  tldr: "We re-define colour refinement and message-passing on Simplicial Complexes, topological generalisation of graphs. This allows to model higher-order interactions, model meso-scale structures and increase the expressive power of Graph Neural Networks."
  co:
    - Cristian Bodnar
    - Yu Guang Wang
  works:
    - https://arxiv.org/abs/2103.03212
-
  month: 4
  year: 2021
  title: "Weisfeiler and Lehman Go Topological: Message Passing Simplicial Networks"
  venue: Math Machine Learning seminar MPI MIS + UCLA
  link: https://media.mis.mpg.de/mml/2021-04-08/
  playback: https://media.mis.mpg.de/mml/2021-04-08/
  slides: https://crisbodnar.github.io/files/mml_talk.pdf
  tldr: "We re-define colour refinement and message-passing on Simplicial Complexes, topological generalisation of graphs. This allows to model higher-order interactions, model meso-scale structures and increase the expressive power of Graph Neural Networks."
  co:
    - Cristian Bodnar
    - Yu Guang Wang
  works:
    - https://arxiv.org/abs/2103.03212
-
  month: 4
  year: 2021
  title: "Improving Graph Neural Network Expressivity via Subgraph Isomorphism Counting"
  venue: Graph Journal Club (Valence AI)
  link: https://twitter.com/valence_ai/status/1377663622407655426
  tldr: "We study how isomorphism counting of small substructures can improve the expressive power of Message Passing Neural Networks, while retaining equivariance, a good inductive bias, and their tractable fwd-pass computational complexity."
  co:
    - Giorgos Bouritsas
  works:
    -  https://arxiv.org/abs/2006.09252
